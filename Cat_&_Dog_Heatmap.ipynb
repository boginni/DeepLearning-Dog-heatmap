{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cat & Dog Heatmap.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOwBxpkSF/K8D47UUW5Ne92",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boginni/DeepLearning-Dog-heatmap/blob/main/Cat_%26_Dog_Heatmap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iXHkT9NwOr1F"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import glob\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/alw4wehyx8gxb1j/dogs-vs-cats.zip?dl=0\n",
        "!unzip /content/dogs-vs-cats.zip?dl=0\n",
        "\n",
        "!unzip /content/train.zip\n",
        "!unzip /content/test1.zip"
      ],
      "metadata": {
        "id": "2kjDFLZDQHDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = \"./DATASET\"\n",
        "\n",
        "ORG_DIR = \"/content/train\"\n",
        "\n",
        "CLASS = ['cat','dog']"
      ],
      "metadata": {
        "id": "qCV2ZrimRAaQ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for C in CLASS:\n",
        "  DEST = os.path.join(TRAIN_DIR, C)\n",
        "\n",
        "  if not os.path.exists(DEST):\n",
        "    os.makedirs(DEST)\n",
        "  \n",
        "  for img_path in glob.glob(os.path.join(ORG_DIR, C) + \"*\"):\n",
        "    SRC = img_path\n",
        "\n",
        "    shutil.copy(SRC, DEST)\n",
        "\n"
      ],
      "metadata": {
        "id": "JO7Zo4ccRWNY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Building"
      ],
      "metadata": {
        "id": "qiGqZp2AVLtI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Model\n",
        "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator , load_img, img_to_array\n"
      ],
      "metadata": {
        "id": "h4sjp3QlVFsC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = InceptionV3(input_shape=(256, 256, 3), include_top=False)"
      ],
      "metadata": {
        "id": "tpM-CFxbWuED"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "gAXbCrxjW5Fy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = Flatten()(base_model.output)\n",
        "X = Dense(units=2, activation='sigmoid')(X)\n",
        "\n",
        "model = Model(base_model.input, X)\n",
        "\n",
        "model.compile(optimizer= 'adam', loss = keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "id": "XEgNEA_uXLgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre Process data"
      ],
      "metadata": {
        "id": "FA0hQIbRhgQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(featurewise_center=True ,\n",
        "                                   rotation_range=0.4, \n",
        "                                   width_shift_range=0.3, \n",
        "                                   horizontal_flip=True,\n",
        "                                   preprocessing_function= preprocess_input, \n",
        "                                   zoom_range= 0.4, \n",
        "                                   shear_range = 0.4)\n",
        "\n",
        "train_data = train_datagen.flow_from_directory(directory = \"/content/DATASET\", \n",
        "                                               target_size=(256, 256), \n",
        "                                               batch_size = 36)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMD4_0DHhd4c",
        "outputId": "220b1762-9977-45a1-cc10-bbdb58cf8824"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VIZUALIZING DATA"
      ],
      "metadata": {
        "id": "snf36Vv5i8Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vqq7Qc9ki3YE",
        "outputId": "739b300a-f1ba-40ea-ec18-8402c6408316"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cat': 0, 'dog': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_img, label = train_data.next()"
      ],
      "metadata": {
        "id": "jTkB65MkkRGS"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plotImages(img_arr, label):\n",
        "  \"\"\"\n",
        "  input : image_array\n",
        "  output: plot images\n",
        "  \"\"\"\n",
        "\n",
        "  for idx, img in enumerate(img_arr) :\n",
        "\n",
        "    if idx <= 10 :\n",
        "\n",
        "      plt.figure(figsize = (5,5))\n",
        "      plt.imshow(img)\n",
        "      plt.title(img.shape)\n",
        "      plt.axis = False\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zi2FMRQrjK5y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plotImages(t_img, label)"
      ],
      "metadata": {
        "id": "oDfMPUI8kNhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL CHECK POINT"
      ],
      "metadata": {
        "id": "UJnpnUMki4Hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "mc  = ModelCheckpoint(filepath = \"./best_model.h5\",\n",
        "                      monitor=\"accuracy\",\n",
        "                      verbose=1,\n",
        "                      save_best_only = True)\n",
        "\n",
        "es = EarlyStopping(monitor = \"accuracy\", \n",
        "                   min_delta= 0.01, \n",
        "                   patience = 5, \n",
        "                   verbose = 1)\n",
        "\n",
        "cb = [mc, es]"
      ],
      "metadata": {
        "id": "vMFwKvzOl94T"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "his = model.fit_generator(train_data, \n",
        "                          steps_per_epoch=10, \n",
        "                          epochs = 30,\n",
        "                          callbacks = cb)"
      ],
      "metadata": {
        "id": "XOPbN2vhmlIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(\"/content/best_model.h5\")"
      ],
      "metadata": {
        "id": "R1nTGlbb0F_E"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = his.history\n",
        "h.keys()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAKdkHOAnwPK",
        "outputId": "555cb8cd-9be2-4fd4-f2ca-93b36fbad0ba"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(h['loss'])\n",
        "plt.plot(h['accuracy'])\n",
        "\n",
        "plt.title(\"loss vs Acc\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZndDtcVk0j8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/test1/10003.jpg\"\n",
        "img = load_img(path, target_size=(256, 256) )\n",
        "\n",
        "i = img_to_array(img)\n",
        "\n",
        "i = preprocess_input(i)\n",
        "\n",
        "input_arr = np.array([i])\n",
        "input_arr.shape\n",
        "\n",
        "pred = np.argmax(model.predict(input_arr))\n",
        "\n",
        "print(pred)\n",
        "\n",
        "if pred == 0:\n",
        "  print(\"The image is of cat\")\n",
        "else:\n",
        "  print(\"the image is of dog\")\n",
        "\n",
        "plt.imshow(input_arr[0])\n",
        "plt.title(\"input image\")\n",
        "plt.axis = False\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "S2aYPWkf1v6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRAD-CAM"
      ],
      "metadata": {
        "id": "g91n-WNx30dm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_img_array(img_path):\n",
        "\n",
        "  img = load_img(img_path, target_size=(256, 256) )\n",
        "\n",
        "  img = img_to_array(img)\n",
        "  img = preprocess_input(img)\n",
        "\n",
        "  input_arr = np.array([img])\n",
        "\n",
        "  return input_arr"
      ],
      "metadata": {
        "id": "FX3d8RPP331E"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "-hQwuNh541Gg"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRADCAM"
      ],
      "metadata": {
        "id": "1cO24T7Ua82H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_gradcamheatmap(img_arr, model, last_conv_layer_name, pred_index = None):\n",
        "  \n",
        "  grad_model = tf.keras.models.Model(\n",
        "      [model.input], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "  )\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    last_conv_layer_output, preds = grad_model(img_arr)\n",
        "\n",
        "    if pred_index is None: \n",
        "      pred_index = tf.argmax(preds[0])\n",
        "    \n",
        "    class_channel = preds[:,pred_index]\n",
        "\n",
        "  grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "  pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n",
        "\n",
        "  last_conv_layer_output = last_conv_layer_output[0]\n",
        "\n",
        "  heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "\n",
        "  heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "  heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "\n",
        "  return heatmap.numpy()\n",
        "\n"
      ],
      "metadata": {
        "id": "Avdg_96B43jJ"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.cm as cm\n",
        "\n",
        "from IPython.display import Image, display"
      ],
      "metadata": {
        "id": "NtexfaZ85ZPS"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_and_display_gradcam(img_path, heatmap, cam_path = \"cam.jpg\", alpha = 0.4):\n",
        "  img = img_to_array(load_img(img_path) )\n",
        "\n",
        "  heatmap = np.uint8(255 * heatmap)\n",
        "\n",
        "  jet = cm.get_cmap(\"jet\")\n",
        "\n",
        "  jet_colors = jet(np.arange(256))[:,:3]\n",
        "  jet_heatmap = jet_colors[heatmap]\n",
        "\n",
        "  jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "  jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "  jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "\n",
        "  superimposed_img = jet_heatmap * alpha + img\n",
        "  superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "\n",
        "\n",
        "  superimposed_img.save(cam_path)\n",
        "\n",
        "  display(Image(cam_path))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KQPJaVdt-2Z2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_prediction_and_visualization(path, last_conv_layer_name = \"conv2d_93\", model = model):\n",
        "\n",
        "\n",
        "  img_array = get_img_array(path)\n",
        "\n",
        "  heatmap = make_gradcamheatmap(img_array, model, last_conv_layer_name)\n",
        "\n",
        "  plt.title(\"the heat map of the image is \")\n",
        "  plt.imshow(heatmap)\n",
        "  plt.show()\n",
        "\n",
        "  pred = np.argmax(model.predict(img_array))\n",
        "  print()\n",
        "  print()\n",
        "  print()\n",
        "\n",
        "  if pred == 0:\n",
        "    print(\"The image is of a Cat\")\n",
        "  else:\n",
        "    print(\"The image is of a Dog\")\n",
        "\n",
        "  print()\n",
        "\n",
        "  save_and_display_gradcam(path, heatmap)\n",
        "\n",
        "  print()\n",
        "  print(\"the original input image\")\n",
        "  print()\n",
        "\n",
        "  a = plt.imread(path)\n",
        "  plt.imshow(a, cmap = \"gray\")\n",
        "  plt.title(\"Original image\")\n",
        "  plt.show()\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "Fclwi7cOAm-1"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/buying-a-dog.jpg\"\n",
        "image_prediction_and_visualization(path)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tqPfznryCJ3g"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}